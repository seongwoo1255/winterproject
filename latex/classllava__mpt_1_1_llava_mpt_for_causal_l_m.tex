\doxysection{llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM Class Reference}
\hypertarget{classllava__mpt_1_1_llava_mpt_for_causal_l_m}{}\label{classllava__mpt_1_1_llava_mpt_for_causal_l_m}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}


LLa\+VA MPT 변형을 통한 Causal Language Model 구현  




Inheritance diagram for llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM\+:
% FIG 0


Collaboration diagram for llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM\+:
% FIG 1
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a54080f01eb1168b3dcc3b21982ed6657}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, \mbox{\hyperlink{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a64f3ed33345e5078777ce464de4ea71b}{config}})
\item 
\mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a1bcc44c4cedd38c0bd542416d32c42af}{get\+\_\+model}} (self)
\begin{DoxyCompactList}\small\item\em 모델 객체를 반환하는 메서드 \end{DoxyCompactList}\item 
\mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_for_causal_l_m_acbbd3b14bba2a12a0d9ca11c83cf071d}{forward}} (self, Optional\mbox{[}torch.\+Long\+Tensor\mbox{]} input\+\_\+ids=None, Optional\mbox{[}Tuple\mbox{[}Tuple\mbox{[}torch.\+Tensor, torch.\+Tensor\mbox{]},...\mbox{]}\mbox{]} past\+\_\+key\+\_\+values=None, Optional\mbox{[}torch.\+Tensor\mbox{]} attention\+\_\+mask=None, Optional\mbox{[}torch.\+Tensor\mbox{]} inputs\+\_\+embeds=None, Optional\mbox{[}torch.\+Tensor\mbox{]} labels=None, Optional\mbox{[}bool\mbox{]} use\+\_\+cache=None, Optional\mbox{[}bool\mbox{]} output\+\_\+attentions=None, Optional\mbox{[}bool\mbox{]} output\+\_\+hidden\+\_\+states=None, Optional\mbox{[}bool\mbox{]} return\+\_\+dict=None, images=None)
\begin{DoxyCompactList}\small\item\em Causal Language Model의 forward 패스를 정의 \end{DoxyCompactList}\item 
\mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a911f26158e7c70fd7bc866f3cfe3a76d}{prepare\+\_\+inputs\+\_\+for\+\_\+generation}} (self, input\+\_\+ids, past\+\_\+key\+\_\+values=None, inputs\+\_\+embeds=None, \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs)
\begin{DoxyCompactList}\small\item\em 텍스트 생성을 위한 입력 데이터를 준비하는 메서드 \end{DoxyCompactList}\item 
\mbox{\hyperlink{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a44dc1290b35b25f8d213b88f7f4abc2a}{get\+\_\+vision\+\_\+tower}} (self)
\begin{DoxyCompactList}\small\item\em 비전 타워를 반환하는 메서드 \end{DoxyCompactList}\item 
\mbox{\hyperlink{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_aee984abd82f234b6d7c9d37eb643ceb3}{encode\+\_\+images}} (self, images)
\begin{DoxyCompactList}\small\item\em 이미지를 인코딩하여 특징 벡터로 변환 \end{DoxyCompactList}\item 
\mbox{\hyperlink{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a34dac38c46ba9a66cc02de107a400c76}{prepare\+\_\+inputs\+\_\+labels\+\_\+for\+\_\+multimodal}} (self, input\+\_\+ids, position\+\_\+ids, attention\+\_\+mask, past\+\_\+key\+\_\+values, labels, images, image\+\_\+sizes=None)
\begin{DoxyCompactList}\small\item\em 멀티모달 입력과 레이블을 준비하는 함수 \end{DoxyCompactList}\item 
\mbox{\hyperlink{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_acae9e9560fa74ae7ba2788d261abc13c}{initialize\+\_\+vision\+\_\+tokenizer}} (self, model\+\_\+args, tokenizer)
\begin{DoxyCompactList}\small\item\em 비전 토크나이저를 초기화하는 메서드 \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_for_causal_l_m_ac42052a3f618ac1d4a164273dbf0c25f}{transformer}} = \mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_model}{Llava\+Mpt\+Model}}(\mbox{\hyperlink{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a64f3ed33345e5078777ce464de4ea71b}{config}})
\item 
\mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a28245ac877e4cd4d45741a71216847bb}{lm\+\_\+head}} = torch.\+nn.\+Linear(config.\+hidden\+\_\+size, config.\+vocab\+\_\+size, bias=False)
\item 
\mbox{\hyperlink{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a64f3ed33345e5078777ce464de4ea71b}{config}} = cur\+\_\+new\+\_\+embed.\+shape\mbox{[}0\mbox{]}
\end{DoxyCompactItemize}
\doxysubsubsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a171d4101cfae1ec6839d83d2e817a0f7}{config\+\_\+class}} = \mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_config}{Llava\+Mpt\+Config}}
\item 
bool \mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a79bba18fb37b45a452b5c331e21836f2}{supports\+\_\+gradient\+\_\+checkpointing}} = True
\end{DoxyCompactItemize}
\doxysubsubsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_for_causal_l_m_afdd26fa5431561be49aa7e42a0ebb3ab}{\+\_\+set\+\_\+gradient\+\_\+checkpointing}} (self, module, value=False)
\begin{DoxyCompactList}\small\item\em Gradient Checkpointing 설정 메서드 \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
LLa\+VA MPT 변형을 통한 Causal Language Model 구현 

\begin{DoxyAuthor}{Author}
이지희(2021113406)
\end{DoxyAuthor}

\begin{DoxyItemize}
\item 멀티모달 입력 데이터를 기반으로 텍스트를 생성하는 모델입니다.
\item MPT 모델과 Vision Encoder의 출력({\ttfamily Hᵥ})을 결합하여 멀티모달 입력({\ttfamily Hₐ})을 생성합니다.
\item 생성된 멀티모달 입력을 바탕으로 텍스트 응답({\ttfamily Xₐ})을 생성합니다. 
\end{DoxyItemize}

Definition at line \mbox{\hyperlink{llava__mpt_8py_source_l00072}{72}} of file \mbox{\hyperlink{llava__mpt_8py_source}{llava\+\_\+mpt.\+py}}.



\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a54080f01eb1168b3dcc3b21982ed6657}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{\_\_init\_\_()}{\_\_init\_\_()}}
{\footnotesize\ttfamily \label{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a54080f01eb1168b3dcc3b21982ed6657} 
llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{config}{}\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{llava__mpt_8py_source_l00076}{76}} of file \mbox{\hyperlink{llava__mpt_8py_source}{llava\+\_\+mpt.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00076\ \ \ \ \ \textcolor{keyword}{def\ }\_\_init\_\_(self,\ config):}
\DoxyCodeLine{00077\ \ \ \ \ \ \ \ \ super(MptForCausalLM,\ self).\_\_init\_\_(config)}
\DoxyCodeLine{00078\ }
\DoxyCodeLine{00079\ \ \ \ \ \ \ \ \ self.transformer\ =\ LlavaMptModel(config)}
\DoxyCodeLine{00080\ \ \ \ \ \ \ \ \ self.lm\_head\ =\ torch.nn.Linear(config.hidden\_size,\ config.vocab\_size,\ bias=\textcolor{keyword}{False})}
\DoxyCodeLine{00081\ }
\DoxyCodeLine{00082\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Initialize\ weights\ and\ apply\ final\ processing}}
\DoxyCodeLine{00083\ \ \ \ \ \ \ \ \ self.post\_init()}
\DoxyCodeLine{00084\ }

\end{DoxyCode}
Here is the call graph for this function\+:
% FIG 2
Here is the caller graph for this function\+:
% FIG 3


\doxysubsection{Member Function Documentation}
\Hypertarget{classllava__mpt_1_1_llava_mpt_for_causal_l_m_afdd26fa5431561be49aa7e42a0ebb3ab}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!\_set\_gradient\_checkpointing@{\_set\_gradient\_checkpointing}}
\index{\_set\_gradient\_checkpointing@{\_set\_gradient\_checkpointing}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{\_set\_gradient\_checkpointing()}{\_set\_gradient\_checkpointing()}}
{\footnotesize\ttfamily \label{classllava__mpt_1_1_llava_mpt_for_causal_l_m_afdd26fa5431561be49aa7e42a0ebb3ab} 
llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM.\+\_\+set\+\_\+gradient\+\_\+checkpointing (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{module}{, }\item[{}]{value}{ = {\ttfamily False}}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}



Gradient Checkpointing 설정 메서드 

\begin{DoxyAuthor}{Author}
이지희(2021113406)
\end{DoxyAuthor}

\begin{DoxyParams}{Parameters}
{\em module} & (torch.\+nn.\+Module) 설정할 모듈 객체 \\
\hline
{\em value} & (bool) Gradient Checkpointing 활성화 여부. 기본값은 {\ttfamily False} \\
\hline
\end{DoxyParams}


Definition at line \mbox{\hyperlink{llava__mpt_8py_source_l00099}{99}} of file \mbox{\hyperlink{llava__mpt_8py_source}{llava\+\_\+mpt.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00099\ \ \ \ \ \textcolor{keyword}{def\ }\_set\_gradient\_checkpointing(self,\ module,\ value=False):}
\DoxyCodeLine{00100\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ isinstance(module,\ LlavaMptModel):}
\DoxyCodeLine{00101\ \ \ \ \ \ \ \ \ \ \ \ \ module.gradient\_checkpointing\ =\ value}
\DoxyCodeLine{00102\ }

\end{DoxyCode}
\Hypertarget{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_aee984abd82f234b6d7c9d37eb643ceb3}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!encode\_images@{encode\_images}}
\index{encode\_images@{encode\_images}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{encode\_images()}{encode\_images()}}
{\footnotesize\ttfamily \label{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_aee984abd82f234b6d7c9d37eb643ceb3} 
llava.\+model.\+llava\+\_\+arch.\+Llava\+Meta\+For\+Causal\+LM.\+encode\+\_\+images (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{images}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inherited]}}



이미지를 인코딩하여 특징 벡터로 변환 

\begin{DoxyAuthor}{Author}
이지희(2021113406)
\end{DoxyAuthor}

\begin{DoxyParams}{Parameters}
{\em images} & 입력 이미지 텐서 \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
이미지 특징 벡터 
\end{DoxyReturn}


Definition at line \mbox{\hyperlink{llava__arch_8py_source_l00213}{213}} of file \mbox{\hyperlink{llava__arch_8py_source}{llava\+\_\+arch.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00213\ \ \ \ \ \textcolor{keyword}{def\ }encode\_images(self,\ images):}
\DoxyCodeLine{00214\ \ \ \ \ \ \ \ \ image\_features\ =\ self.get\_model().get\_vision\_tower()(images)}
\DoxyCodeLine{00215\ \ \ \ \ \ \ \ \ image\_features\ =\ self.get\_model().mm\_projector(image\_features)}
\DoxyCodeLine{00216\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ image\_features}
\DoxyCodeLine{00217\ }

\end{DoxyCode}
Here is the call graph for this function\+:
% FIG 4
Here is the caller graph for this function\+:
% FIG 5
\Hypertarget{classllava__mpt_1_1_llava_mpt_for_causal_l_m_acbbd3b14bba2a12a0d9ca11c83cf071d}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!forward@{forward}}
\index{forward@{forward}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{forward()}{forward()}}
{\footnotesize\ttfamily \label{classllava__mpt_1_1_llava_mpt_for_causal_l_m_acbbd3b14bba2a12a0d9ca11c83cf071d} 
llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM.\+forward (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{Optional\mbox{[}torch.\+Long\+Tensor\mbox{]} }]{input\+\_\+ids}{ = {\ttfamily None}, }\item[{Optional\mbox{[}Tuple\mbox{[}Tuple\mbox{[}torch.\+Tensor, torch.\+Tensor\mbox{]}, ...\mbox{]}\mbox{]} }]{past\+\_\+key\+\_\+values}{ = {\ttfamily None}, }\item[{Optional\mbox{[}torch.\+Tensor\mbox{]} }]{attention\+\_\+mask}{ = {\ttfamily None}, }\item[{Optional\mbox{[}torch.\+Tensor\mbox{]} }]{inputs\+\_\+embeds}{ = {\ttfamily None}, }\item[{Optional\mbox{[}torch.\+Tensor\mbox{]} }]{labels}{ = {\ttfamily None}, }\item[{Optional\mbox{[}bool\mbox{]} }]{use\+\_\+cache}{ = {\ttfamily None}, }\item[{Optional\mbox{[}bool\mbox{]} }]{output\+\_\+attentions}{ = {\ttfamily None}, }\item[{Optional\mbox{[}bool\mbox{]} }]{output\+\_\+hidden\+\_\+states}{ = {\ttfamily None}, }\item[{Optional\mbox{[}bool\mbox{]} }]{return\+\_\+dict}{ = {\ttfamily None}, }\item[{}]{images}{ = {\ttfamily None}}\end{DoxyParamCaption})}



Causal Language Model의 forward 패스를 정의 

\begin{DoxyAuthor}{Author}
이지희(2021113406)
\end{DoxyAuthor}

\begin{DoxyParams}{Parameters}
{\em input\+\_\+ids} & (torch.\+Long\+Tensor) 텍스트 입력 토큰 ID. (optional) \\
\hline
{\em past\+\_\+key\+\_\+values} & (Tuple\mbox{[}torch.\+Tensor, torch.\+Tensor\mbox{]}) 이전 키/값 캐시. 디코더에서 사용. (optional) \\
\hline
{\em attention\+\_\+mask} & (torch.\+Tensor) 입력 텍스트에 대한 어텐션 마스크. (optional) \\
\hline
{\em inputs\+\_\+embeds} & (torch.\+Tensor) 입력 텍스트 임베딩. (optional) \\
\hline
{\em labels} & (torch.\+Tensor) 학습 시 사용할 정답 레이블. (optional) \\
\hline
{\em use\+\_\+cache} & (bool) 이전 키/값 캐시를 사용할지 여부. (optional) \\
\hline
{\em output\+\_\+attentions} & (bool) 어텐션 가중치를 출력할지 여부. (optional) \\
\hline
{\em output\+\_\+hidden\+\_\+states} & (bool) 히든 상태를 출력할지 여부. (optional) \\
\hline
{\em return\+\_\+dict} & (bool) 반환 값을 딕셔너리 형태로 출력할지 여부. (optional) \\
\hline
{\em images} & (torch.\+Tensor) 입력 이미지 데이터. (optional)\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}

\begin{DoxyItemize}
\item torch.\+Tensor\+: 모델의 출력. 텍스트 생성 결과와 필요시 어텐션 정보, 히든 상태를 포함. 
\end{DoxyItemize}
\end{DoxyReturn}


Definition at line \mbox{\hyperlink{llava__mpt_8py_source_l00120}{120}} of file \mbox{\hyperlink{llava__mpt_8py_source}{llava\+\_\+mpt.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00131\ \ \ \ \ \ \ \ \ images=\textcolor{keywordtype}{None}):}
\DoxyCodeLine{00132\ }
\DoxyCodeLine{00133\ \ \ \ \ \ \ \ \ input\_ids,\ attention\_mask,\ past\_key\_values,\ inputs\_embeds,\ labels\ =\ self.prepare\_inputs\_labels\_for\_multimodal(input\_ids,\ attention\_mask,\ past\_key\_values,\ labels,\ images)}
\DoxyCodeLine{00134\ }
\DoxyCodeLine{00135\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ super().forward(}
\DoxyCodeLine{00136\ \ \ \ \ \ \ \ \ \ \ \ \ input\_ids,}
\DoxyCodeLine{00137\ \ \ \ \ \ \ \ \ \ \ \ \ past\_key\_values=past\_key\_values,}
\DoxyCodeLine{00138\ \ \ \ \ \ \ \ \ \ \ \ \ attention\_mask=attention\_mask,}
\DoxyCodeLine{00139\ \ \ \ \ \ \ \ \ \ \ \ \ inputs\_embeds=inputs\_embeds,}
\DoxyCodeLine{00140\ \ \ \ \ \ \ \ \ \ \ \ \ labels=labels,}
\DoxyCodeLine{00141\ \ \ \ \ \ \ \ \ \ \ \ \ use\_cache=use\_cache,}
\DoxyCodeLine{00142\ \ \ \ \ \ \ \ \ \ \ \ \ output\_attentions=output\_attentions,}
\DoxyCodeLine{00143\ \ \ \ \ \ \ \ \ \ \ \ \ output\_hidden\_states=output\_hidden\_states,}
\DoxyCodeLine{00144\ \ \ \ \ \ \ \ \ \ \ \ \ return\_dict=return\_dict,}
\DoxyCodeLine{00145\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{00146\ }

\end{DoxyCode}
Here is the call graph for this function\+:
% FIG 6
Here is the caller graph for this function\+:
% FIG 7
\Hypertarget{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a1bcc44c4cedd38c0bd542416d32c42af}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!get\_model@{get\_model}}
\index{get\_model@{get\_model}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{get\_model()}{get\_model()}}
{\footnotesize\ttfamily \label{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a1bcc44c4cedd38c0bd542416d32c42af} 
llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM.\+get\+\_\+model (\begin{DoxyParamCaption}\item[{}]{self}{}\end{DoxyParamCaption})}



모델 객체를 반환하는 메서드 

\begin{DoxyAuthor}{Author}
이지희(2021113406)
\end{DoxyAuthor}
\begin{DoxyReturn}{Returns}
\doxylink{classllava__mpt_1_1_llava_mpt_model}{Llava\+Mpt\+Model}\+: MPT 기반 LLa\+VA 모델 객체 
\end{DoxyReturn}


Reimplemented from \mbox{\hyperlink{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a63a2680e7cef4f40b17446aa6d4f0855}{llava.\+model.\+llava\+\_\+arch.\+Llava\+Meta\+For\+Causal\+LM}}.



Definition at line \mbox{\hyperlink{llava__mpt_8py_source_l00090}{90}} of file \mbox{\hyperlink{llava__mpt_8py_source}{llava\+\_\+mpt.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00090\ \ \ \ \ \textcolor{keyword}{def\ }get\_model(self):}
\DoxyCodeLine{00091\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.transformer}
\DoxyCodeLine{00092\ }

\end{DoxyCode}
Here is the caller graph for this function\+:
% FIG 8
\Hypertarget{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a44dc1290b35b25f8d213b88f7f4abc2a}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!get\_vision\_tower@{get\_vision\_tower}}
\index{get\_vision\_tower@{get\_vision\_tower}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{get\_vision\_tower()}{get\_vision\_tower()}}
{\footnotesize\ttfamily \label{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a44dc1290b35b25f8d213b88f7f4abc2a} 
llava.\+model.\+llava\+\_\+arch.\+Llava\+Meta\+For\+Causal\+LM.\+get\+\_\+vision\+\_\+tower (\begin{DoxyParamCaption}\item[{}]{self}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inherited]}}



비전 타워를 반환하는 메서드 

\begin{DoxyAuthor}{Author}
이지희(2021113406)
\end{DoxyAuthor}
\begin{DoxyReturn}{Returns}
비전 타워 객체 
\end{DoxyReturn}


Definition at line \mbox{\hyperlink{llava__arch_8py_source_l00204}{204}} of file \mbox{\hyperlink{llava__arch_8py_source}{llava\+\_\+arch.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00204\ \ \ \ \ \textcolor{keyword}{def\ }get\_vision\_tower(self):}
\DoxyCodeLine{00205\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ self.get\_model().get\_vision\_tower()}
\DoxyCodeLine{00206\ }

\end{DoxyCode}
Here is the call graph for this function\+:
% FIG 9
Here is the caller graph for this function\+:
% FIG 10
\Hypertarget{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_acae9e9560fa74ae7ba2788d261abc13c}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!initialize\_vision\_tokenizer@{initialize\_vision\_tokenizer}}
\index{initialize\_vision\_tokenizer@{initialize\_vision\_tokenizer}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{initialize\_vision\_tokenizer()}{initialize\_vision\_tokenizer()}}
{\footnotesize\ttfamily \label{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_acae9e9560fa74ae7ba2788d261abc13c} 
llava.\+model.\+llava\+\_\+arch.\+Llava\+Meta\+For\+Causal\+LM.\+initialize\+\_\+vision\+\_\+tokenizer (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{model\+\_\+args}{, }\item[{}]{tokenizer}{}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inherited]}}



비전 토크나이저를 초기화하는 메서드 

\begin{DoxyAuthor}{Author}
이지희(2021113406)
\end{DoxyAuthor}

\begin{DoxyParams}{Parameters}
{\em model\+\_\+args} & 모델 설정 정보 \\
\hline
{\em tokenizer} & 토크나이저 객체 \\
\hline
\end{DoxyParams}


Definition at line \mbox{\hyperlink{llava__arch_8py_source_l00420}{420}} of file \mbox{\hyperlink{llava__arch_8py_source}{llava\+\_\+arch.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00420\ \ \ \ \ \textcolor{keyword}{def\ }initialize\_vision\_tokenizer(self,\ model\_args,\ tokenizer):}
\DoxyCodeLine{00421\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ model\_args.mm\_use\_im\_patch\_token:}
\DoxyCodeLine{00422\ \ \ \ \ \ \ \ \ \ \ \ \ tokenizer.add\_tokens([DEFAULT\_IMAGE\_PATCH\_TOKEN],\ special\_tokens=\textcolor{keyword}{True})}
\DoxyCodeLine{00423\ \ \ \ \ \ \ \ \ \ \ \ \ self.resize\_token\_embeddings(len(tokenizer))}
\DoxyCodeLine{00424\ }
\DoxyCodeLine{00425\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ model\_args.mm\_use\_im\_start\_end:}
\DoxyCodeLine{00426\ \ \ \ \ \ \ \ \ \ \ \ \ num\_new\_tokens\ =\ tokenizer.add\_tokens([DEFAULT\_IM\_START\_TOKEN,\ DEFAULT\_IM\_END\_TOKEN],\ special\_tokens=\textcolor{keyword}{True})}
\DoxyCodeLine{00427\ \ \ \ \ \ \ \ \ \ \ \ \ self.resize\_token\_embeddings(len(tokenizer))}
\DoxyCodeLine{00428\ }
\DoxyCodeLine{00429\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ num\_new\_tokens\ >\ 0:}
\DoxyCodeLine{00430\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ input\_embeddings\ =\ self.get\_input\_embeddings().weight.data}
\DoxyCodeLine{00431\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ output\_embeddings\ =\ self.get\_output\_embeddings().weight.data}
\DoxyCodeLine{00432\ }
\DoxyCodeLine{00433\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ input\_embeddings\_avg\ =\ input\_embeddings[:-\/num\_new\_tokens].mean(}
\DoxyCodeLine{00434\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ dim=0,\ keepdim=\textcolor{keyword}{True})}
\DoxyCodeLine{00435\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ output\_embeddings\_avg\ =\ output\_embeddings[:-\/num\_new\_tokens].mean(}
\DoxyCodeLine{00436\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ dim=0,\ keepdim=\textcolor{keyword}{True})}
\DoxyCodeLine{00437\ }
\DoxyCodeLine{00438\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ input\_embeddings[-\/num\_new\_tokens:]\ =\ input\_embeddings\_avg}
\DoxyCodeLine{00439\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ output\_embeddings[-\/num\_new\_tokens:]\ =\ output\_embeddings\_avg}
\DoxyCodeLine{00440\ }
\DoxyCodeLine{00441\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ model\_args.tune\_mm\_mlp\_adapter:}
\DoxyCodeLine{00442\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ p\ \textcolor{keywordflow}{in}\ self.get\_input\_embeddings().parameters():}
\DoxyCodeLine{00443\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ p.requires\_grad\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{00444\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ p\ \textcolor{keywordflow}{in}\ self.get\_output\_embeddings().parameters():}
\DoxyCodeLine{00445\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ p.requires\_grad\ =\ \textcolor{keyword}{False}}
\DoxyCodeLine{00446\ }
\DoxyCodeLine{00447\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ model\_args.pretrain\_mm\_mlp\_adapter:}
\DoxyCodeLine{00448\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ mm\_projector\_weights\ =\ torch.load(model\_args.pretrain\_mm\_mlp\_adapter,\ map\_location=\textcolor{stringliteral}{'cpu'})}
\DoxyCodeLine{00449\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ embed\_tokens\_weight\ =\ mm\_projector\_weights[\textcolor{stringliteral}{'model.embed\_tokens.weight'}]}
\DoxyCodeLine{00450\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ num\_new\_tokens\ ==\ 2}
\DoxyCodeLine{00451\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ input\_embeddings.shape\ ==\ embed\_tokens\_weight.shape:}
\DoxyCodeLine{00452\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ input\_embeddings[-\/num\_new\_tokens:]\ =\ embed\_tokens\_weight[-\/num\_new\_tokens:]}
\DoxyCodeLine{00453\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{elif}\ embed\_tokens\_weight.shape[0]\ ==\ num\_new\_tokens:}
\DoxyCodeLine{00454\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ input\_embeddings[-\/num\_new\_tokens:]\ =\ embed\_tokens\_weight}
\DoxyCodeLine{00455\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{00456\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ ValueError(f\textcolor{stringliteral}{"{}Unexpected\ embed\_tokens\_weight\ shape.\ Pretrained:\ \{embed\_tokens\_weight.shape\}.\ Current:\ \{input\_embeddings.shape\}.\ Numer\ of\ new\ tokens:\ \{num\_new\_tokens\}."{}})}
\DoxyCodeLine{00457\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{elif}\ model\_args.mm\_use\_im\_patch\_token:}
\DoxyCodeLine{00458\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ model\_args.tune\_mm\_mlp\_adapter:}
\DoxyCodeLine{00459\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ p\ \textcolor{keywordflow}{in}\ self.get\_input\_embeddings().parameters():}
\DoxyCodeLine{00460\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ p.requires\_grad\ =\ \textcolor{keyword}{False}}
\DoxyCodeLine{00461\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ p\ \textcolor{keywordflow}{in}\ self.get\_output\_embeddings().parameters():}
\DoxyCodeLine{00462\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ p.requires\_grad\ =\ \textcolor{keyword}{False}}

\end{DoxyCode}
\Hypertarget{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a911f26158e7c70fd7bc866f3cfe3a76d}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!prepare\_inputs\_for\_generation@{prepare\_inputs\_for\_generation}}
\index{prepare\_inputs\_for\_generation@{prepare\_inputs\_for\_generation}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{prepare\_inputs\_for\_generation()}{prepare\_inputs\_for\_generation()}}
{\footnotesize\ttfamily \label{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a911f26158e7c70fd7bc866f3cfe3a76d} 
llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM.\+prepare\+\_\+inputs\+\_\+for\+\_\+generation (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{input\+\_\+ids}{, }\item[{}]{past\+\_\+key\+\_\+values}{ = {\ttfamily None}, }\item[{}]{inputs\+\_\+embeds}{ = {\ttfamily None}, }\item[{\texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}}]{kwargs}{}\end{DoxyParamCaption})}



텍스트 생성을 위한 입력 데이터를 준비하는 메서드 

\begin{DoxyAuthor}{Author}
이지희(2021113406)
\end{DoxyAuthor}

\begin{DoxyItemize}
\item 입력 텍스트와 이미지 데이터를 모델이 처리할 수 있는 형태로 변환합니다.
\item {\ttfamily super().prepare\+\_\+inputs\+\_\+for\+\_\+generation}을 호출하여 기본 텍스트 데이터를 준비하고, 추가적으로 이미지 데이터를 포함합니다.
\end{DoxyItemize}


\begin{DoxyParams}{Parameters}
{\em input\+\_\+ids} & (torch.\+Long\+Tensor) 텍스트 입력 토큰 ID. \\
\hline
{\em past\+\_\+key\+\_\+values} & (Tuple\mbox{[}torch.\+Tensor, torch.\+Tensor\mbox{]}) 이전 키/값 캐시. 디코더에서 사용. (optional) \\
\hline
{\em inputs\+\_\+embeds} & (torch.\+Tensor) 입력 텍스트 임베딩. (optional) \\
\hline
{\em \texorpdfstring{$\ast$}{*}\texorpdfstring{$\ast$}{*}kwargs} & 추가 매개변수. 이미지 데이터({\ttfamily images})와 기타 설정 정보를 포함.\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}

\begin{DoxyItemize}
\item dict\+: 준비된 입력 데이터 딕셔너리
\item 포함 항목\+:
\begin{DoxyItemize}
\item {\ttfamily input\+\_\+ids}\+: 텍스트 입력 토큰 ID
\item {\ttfamily past\+\_\+key\+\_\+values}\+: 이전 키/값 캐시
\item {\ttfamily inputs\+\_\+embeds}\+: 텍스트 임베딩
\item {\ttfamily images}\+: 이미지 데이터 
\end{DoxyItemize}
\end{DoxyItemize}
\end{DoxyReturn}


Definition at line \mbox{\hyperlink{llava__mpt_8py_source_l00168}{168}} of file \mbox{\hyperlink{llava__mpt_8py_source}{llava\+\_\+mpt.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00168\ \ \ \ \ \textcolor{keyword}{def\ }prepare\_inputs\_for\_generation(self,\ input\_ids,\ past\_key\_values=None,\ inputs\_embeds=None,\ **kwargs):}
\DoxyCodeLine{00169\ \ \ \ \ \ \ \ \ images\ =\ kwargs.pop(\textcolor{stringliteral}{"{}images"{}},\ \textcolor{keywordtype}{None})}
\DoxyCodeLine{00170\ \ \ \ \ \ \ \ \ \_inputs\ =\ super().prepare\_inputs\_for\_generation(}
\DoxyCodeLine{00171\ \ \ \ \ \ \ \ \ \ \ \ \ input\_ids,\ past\_key\_values=past\_key\_values,\ inputs\_embeds=inputs\_embeds,\ **kwargs}
\DoxyCodeLine{00172\ \ \ \ \ \ \ \ \ )}
\DoxyCodeLine{00173\ \ \ \ \ \ \ \ \ \_inputs[\textcolor{stringliteral}{'images'}]\ =\ images}
\DoxyCodeLine{00174\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \_inputs}
\DoxyCodeLine{00175\ }

\end{DoxyCode}
Here is the call graph for this function\+:
% FIG 11
Here is the caller graph for this function\+:
% FIG 12
\Hypertarget{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a34dac38c46ba9a66cc02de107a400c76}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!prepare\_inputs\_labels\_for\_multimodal@{prepare\_inputs\_labels\_for\_multimodal}}
\index{prepare\_inputs\_labels\_for\_multimodal@{prepare\_inputs\_labels\_for\_multimodal}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{prepare\_inputs\_labels\_for\_multimodal()}{prepare\_inputs\_labels\_for\_multimodal()}}
{\footnotesize\ttfamily \label{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a34dac38c46ba9a66cc02de107a400c76} 
llava.\+model.\+llava\+\_\+arch.\+Llava\+Meta\+For\+Causal\+LM.\+prepare\+\_\+inputs\+\_\+labels\+\_\+for\+\_\+multimodal (\begin{DoxyParamCaption}\item[{}]{self}{, }\item[{}]{input\+\_\+ids}{, }\item[{}]{position\+\_\+ids}{, }\item[{}]{attention\+\_\+mask}{, }\item[{}]{past\+\_\+key\+\_\+values}{, }\item[{}]{labels}{, }\item[{}]{images}{, }\item[{}]{image\+\_\+sizes}{ = {\ttfamily None}}\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inherited]}}



멀티모달 입력과 레이블을 준비하는 함수 

\begin{DoxyAuthor}{Author}
이지희(2021113406)
\end{DoxyAuthor}

\begin{DoxyParams}{Parameters}
{\em input\+\_\+ids} & 텍스트 입력 토큰 ID \\
\hline
{\em position\+\_\+ids} & 위치 정보 ID \\
\hline
{\em attention\+\_\+mask} & 어텐션 마스크 \\
\hline
{\em past\+\_\+key\+\_\+values} & 이전 키/값 캐시 (디코더) \\
\hline
{\em labels} & 텍스트 레이블 \\
\hline
{\em images} & 입력 이미지 텐서 \\
\hline
{\em image\+\_\+sizes} & 이미지 크기 정보 (선택 사항) \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
(position\+\_\+ids, attention\+\_\+mask, past\+\_\+key\+\_\+values, 새로운 입력 임베딩, 새로운 레이블) 튜플 
\end{DoxyReturn}


Definition at line \mbox{\hyperlink{llava__arch_8py_source_l00230}{230}} of file \mbox{\hyperlink{llava__arch_8py_source}{llava\+\_\+arch.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00233\ \ \ \ \ ):}
\DoxyCodeLine{00234\ \ \ \ \ \ \ \ \ vision\_tower\ =\ self.get\_vision\_tower()}
\DoxyCodeLine{00235\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ vision\_tower\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}\ \textcolor{keywordflow}{or}\ images\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}\ \textcolor{keywordflow}{or}\ input\_ids.shape[1]\ ==\ 1:}
\DoxyCodeLine{00236\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ input\_ids,\ position\_ids,\ attention\_mask,\ past\_key\_values,\ \textcolor{keywordtype}{None},\ labels}
\DoxyCodeLine{00237\ }
\DoxyCodeLine{00238\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ 이미지가\ 여러\ 개일\ 경우\ 처리}}
\DoxyCodeLine{00239\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ type(images)\ \textcolor{keywordflow}{is}\ list\ \textcolor{keywordflow}{or}\ images.ndim\ ==\ 5:}
\DoxyCodeLine{00240\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ type(images)\ \textcolor{keywordflow}{is}\ list:}
\DoxyCodeLine{00241\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ images\ =\ [x.unsqueeze(0)\ \textcolor{keywordflow}{if}\ x.ndim\ ==\ 3\ \textcolor{keywordflow}{else}\ x\ \textcolor{keywordflow}{for}\ x\ \textcolor{keywordflow}{in}\ images]}
\DoxyCodeLine{00242\ \ \ \ \ \ \ \ \ \ \ \ \ concat\_images\ =\ torch.cat([image\ \textcolor{keywordflow}{for}\ image\ \textcolor{keywordflow}{in}\ images],\ dim=0)}
\DoxyCodeLine{00243\ \ \ \ \ \ \ \ \ \ \ \ \ image\_features\ =\ self.encode\_images(concat\_images)}
\DoxyCodeLine{00244\ \ \ \ \ \ \ \ \ \ \ \ \ split\_sizes\ =\ [image.shape[0]\ \textcolor{keywordflow}{for}\ image\ \textcolor{keywordflow}{in}\ images]}
\DoxyCodeLine{00245\ \ \ \ \ \ \ \ \ \ \ \ \ image\_features\ =\ torch.split(image\_features,\ split\_sizes,\ dim=0)}
\DoxyCodeLine{00246\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ 멀티모달\ 패치\ 병합\ 타입\ 처리}}
\DoxyCodeLine{00247\ \ \ \ \ \ \ \ \ \ \ \ \ mm\_patch\_merge\_type\ =\ getattr(self.config,\ \textcolor{stringliteral}{'mm\_patch\_merge\_type'},\ \textcolor{stringliteral}{'flat'})}
\DoxyCodeLine{00248\ \ \ \ \ \ \ \ \ \ \ \ \ image\_aspect\_ratio\ =\ getattr(self.config,\ \textcolor{stringliteral}{'image\_aspect\_ratio'},\ \textcolor{stringliteral}{'square'})}
\DoxyCodeLine{00249\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ mm\_patch\_merge\_type\ ==\ \textcolor{stringliteral}{'flat'}:}
\DoxyCodeLine{00250\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_features\ =\ [x.flatten(0,\ 1)\ \textcolor{keywordflow}{for}\ x\ \textcolor{keywordflow}{in}\ image\_features]}
\DoxyCodeLine{00251\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{elif}\ mm\_patch\_merge\_type.startswith(\textcolor{stringliteral}{'spatial'}):}
\DoxyCodeLine{00252\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ new\_image\_features\ =\ []}
\DoxyCodeLine{00253\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ image\_idx,\ image\_feature\ \textcolor{keywordflow}{in}\ enumerate(image\_features):}
\DoxyCodeLine{00254\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ image\_feature.shape[0]\ >\ 1:}
\DoxyCodeLine{00255\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ base\_image\_feature\ =\ image\_feature[0]}
\DoxyCodeLine{00256\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ image\_feature[1:]}
\DoxyCodeLine{00257\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ height\ =\ width\ =\ self.get\_vision\_tower().num\_patches\_per\_side}
\DoxyCodeLine{00258\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keyword}{assert}\ height\ *\ width\ ==\ base\_image\_feature.shape[0]}
\DoxyCodeLine{00259\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ image\_aspect\_ratio\ ==\ \textcolor{stringliteral}{'anyres'}:}
\DoxyCodeLine{00260\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ num\_patch\_width,\ num\_patch\_height\ =\ get\_anyres\_image\_grid\_shape(image\_sizes[image\_idx],\ self.config.image\_grid\_pinpoints,\ self.get\_vision\_tower().config.image\_size)}
\DoxyCodeLine{00261\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ image\_feature.view(num\_patch\_height,\ num\_patch\_width,\ height,\ width,\ -\/1)}
\DoxyCodeLine{00262\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{00263\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ NotImplementedError}
\DoxyCodeLine{00264\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{stringliteral}{'unpad'}\ \textcolor{keywordflow}{in}\ mm\_patch\_merge\_type:}
\DoxyCodeLine{00265\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ image\_feature.permute(4,\ 0,\ 2,\ 1,\ 3).contiguous()}
\DoxyCodeLine{00266\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ image\_feature.flatten(1,\ 2).flatten(2,\ 3)}
\DoxyCodeLine{00267\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ unpad\_image(image\_feature,\ image\_sizes[image\_idx])}
\DoxyCodeLine{00268\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ torch.cat((}
\DoxyCodeLine{00269\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature,}
\DoxyCodeLine{00270\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.model.image\_newline[:,\ \textcolor{keywordtype}{None},\ \textcolor{keywordtype}{None}].expand(*image\_feature.shape[:-\/1],\ 1).to(image\_feature.device)}
\DoxyCodeLine{00271\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ),\ dim=-\/1)}
\DoxyCodeLine{00272\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ image\_feature.flatten(1,\ 2).transpose(0,\ 1)}
\DoxyCodeLine{00273\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{00274\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ image\_feature.permute(0,\ 2,\ 1,\ 3,\ 4).contiguous()}
\DoxyCodeLine{00275\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ image\_feature.flatten(0,\ 3)}
\DoxyCodeLine{00276\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ torch.cat((base\_image\_feature,\ image\_feature),\ dim=0)}
\DoxyCodeLine{00277\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{00278\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ image\_feature[0]}
\DoxyCodeLine{00279\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \textcolor{stringliteral}{'unpad'}\ \textcolor{keywordflow}{in}\ mm\_patch\_merge\_type:}
\DoxyCodeLine{00280\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature\ =\ torch.cat((}
\DoxyCodeLine{00281\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_feature,}
\DoxyCodeLine{00282\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ self.model.image\_newline[\textcolor{keywordtype}{None}].to(image\_feature.device)}
\DoxyCodeLine{00283\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ),\ dim=0)}
\DoxyCodeLine{00284\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ new\_image\_features.append(image\_feature)}
\DoxyCodeLine{00285\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ image\_features\ =\ new\_image\_features}
\DoxyCodeLine{00286\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{00287\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ ValueError(f\textcolor{stringliteral}{"{}Unexpected\ mm\_patch\_merge\_type:\ \{self.config.mm\_patch\_merge\_type\}"{}})}
\DoxyCodeLine{00288\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{00289\ \ \ \ \ \ \ \ \ \ \ \ \ image\_features\ =\ self.encode\_images(images)}
\DoxyCodeLine{00290\ }
\DoxyCodeLine{00291\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ TODO:\ image\ start\ /\ end\ is\ not\ implemented\ here\ to\ support\ pretraining.}}
\DoxyCodeLine{00292\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ getattr(self.config,\ \textcolor{stringliteral}{'tune\_mm\_mlp\_adapter'},\ \textcolor{keyword}{False})\ \textcolor{keywordflow}{and}\ getattr(self.config,\ \textcolor{stringliteral}{'mm\_use\_im\_start\_end'},\ \textcolor{keyword}{False}):}
\DoxyCodeLine{00293\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{raise}\ NotImplementedError}
\DoxyCodeLine{00294\ }
\DoxyCodeLine{00295\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Let's\ just\ add\ dummy\ tensors\ if\ they\ do\ not\ exist,}}
\DoxyCodeLine{00296\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ it\ is\ a\ headache\ to\ deal\ with\ None\ all\ the\ time.}}
\DoxyCodeLine{00297\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ But\ it\ is\ not\ ideal,\ and\ if\ you\ have\ a\ better\ idea,}}
\DoxyCodeLine{00298\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ please\ open\ an\ issue\ /\ submit\ a\ PR,\ thanks.}}
\DoxyCodeLine{00299\ \ \ \ \ \ \ \ \ \_labels\ =\ labels}
\DoxyCodeLine{00300\ \ \ \ \ \ \ \ \ \_position\_ids\ =\ position\_ids}
\DoxyCodeLine{00301\ \ \ \ \ \ \ \ \ \_attention\_mask\ =\ attention\_mask}
\DoxyCodeLine{00302\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ attention\_mask\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{00303\ \ \ \ \ \ \ \ \ \ \ \ \ attention\_mask\ =\ torch.ones\_like(input\_ids,\ dtype=torch.bool)}
\DoxyCodeLine{00304\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{00305\ \ \ \ \ \ \ \ \ \ \ \ \ attention\_mask\ =\ attention\_mask.bool()}
\DoxyCodeLine{00306\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ position\_ids\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{00307\ \ \ \ \ \ \ \ \ \ \ \ \ position\_ids\ =\ torch.arange(0,\ input\_ids.shape[1],\ dtype=torch.long,\ device=input\_ids.device)}
\DoxyCodeLine{00308\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ labels\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{00309\ \ \ \ \ \ \ \ \ \ \ \ \ labels\ =\ torch.full\_like(input\_ids,\ IGNORE\_INDEX)}
\DoxyCodeLine{00310\ }
\DoxyCodeLine{00311\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ remove\ the\ padding\ using\ attention\_mask\ -\/-\/\ FIXME}}
\DoxyCodeLine{00312\ \ \ \ \ \ \ \ \ \_input\_ids\ =\ input\_ids}
\DoxyCodeLine{00313\ \ \ \ \ \ \ \ \ input\_ids\ =\ [cur\_input\_ids[cur\_attention\_mask]\ \textcolor{keywordflow}{for}\ cur\_input\_ids,\ cur\_attention\_mask\ \textcolor{keywordflow}{in}\ zip(input\_ids,\ attention\_mask)]}
\DoxyCodeLine{00314\ \ \ \ \ \ \ \ \ labels\ =\ [cur\_labels[cur\_attention\_mask]\ \textcolor{keywordflow}{for}\ cur\_labels,\ cur\_attention\_mask\ \textcolor{keywordflow}{in}\ zip(labels,\ attention\_mask)]}
\DoxyCodeLine{00315\ }
\DoxyCodeLine{00316\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ 입력\ 데이터에\ 이미지\ 특징\ 추가}}
\DoxyCodeLine{00317\ \ \ \ \ \ \ \ \ new\_input\_embeds\ =\ []}
\DoxyCodeLine{00318\ \ \ \ \ \ \ \ \ new\_labels\ =\ []}
\DoxyCodeLine{00319\ \ \ \ \ \ \ \ \ cur\_image\_idx\ =\ 0}
\DoxyCodeLine{00320\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ batch\_idx,\ cur\_input\_ids\ \textcolor{keywordflow}{in}\ enumerate(input\_ids):}
\DoxyCodeLine{00321\ \ \ \ \ \ \ \ \ \ \ \ \ num\_images\ =\ (cur\_input\_ids\ ==\ IMAGE\_TOKEN\_INDEX).sum()}
\DoxyCodeLine{00322\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ num\_images\ ==\ 0:}
\DoxyCodeLine{00323\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_image\_features\ =\ image\_features[cur\_image\_idx]}
\DoxyCodeLine{00324\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_input\_embeds\_1\ =\ self.get\_model().embed\_tokens(cur\_input\_ids)}
\DoxyCodeLine{00325\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_input\_embeds\ =\ torch.cat([cur\_input\_embeds\_1,\ cur\_image\_features[0:0]],\ dim=0)}
\DoxyCodeLine{00326\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ new\_input\_embeds.append(cur\_input\_embeds)}
\DoxyCodeLine{00327\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ new\_labels.append(labels[batch\_idx])}
\DoxyCodeLine{00328\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_image\_idx\ +=\ 1}
\DoxyCodeLine{00329\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{continue}}
\DoxyCodeLine{00330\ }
\DoxyCodeLine{00331\ \ \ \ \ \ \ \ \ \ \ \ \ image\_token\_indices\ =\ [-\/1]\ +\ torch.where(cur\_input\_ids\ ==\ IMAGE\_TOKEN\_INDEX)[0].tolist()\ +\ [cur\_input\_ids.shape[0]]}
\DoxyCodeLine{00332\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_input\_ids\_noim\ =\ []}
\DoxyCodeLine{00333\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_labels\ =\ labels[batch\_idx]}
\DoxyCodeLine{00334\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_labels\_noim\ =\ []}
\DoxyCodeLine{00335\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(len(image\_token\_indices)\ -\/\ 1):}
\DoxyCodeLine{00336\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_input\_ids\_noim.append(cur\_input\_ids[image\_token\_indices[i]+1:image\_token\_indices[i+1]])}
\DoxyCodeLine{00337\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_labels\_noim.append(cur\_labels[image\_token\_indices[i]+1:image\_token\_indices[i+1]])}
\DoxyCodeLine{00338\ \ \ \ \ \ \ \ \ \ \ \ \ split\_sizes\ =\ [x.shape[0]\ \textcolor{keywordflow}{for}\ x\ \textcolor{keywordflow}{in}\ cur\_labels\_noim]}
\DoxyCodeLine{00339\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_input\_embeds\ =\ self.get\_model().embed\_tokens(torch.cat(cur\_input\_ids\_noim))}
\DoxyCodeLine{00340\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_input\_embeds\_no\_im\ =\ torch.split(cur\_input\_embeds,\ split\_sizes,\ dim=0)}
\DoxyCodeLine{00341\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_input\_embeds\ =\ []}
\DoxyCodeLine{00342\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_labels\ =\ []}
\DoxyCodeLine{00343\ }
\DoxyCodeLine{00344\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ i\ \textcolor{keywordflow}{in}\ range(num\_images\ +\ 1):}
\DoxyCodeLine{00345\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_input\_embeds.append(cur\_input\_embeds\_no\_im[i])}
\DoxyCodeLine{00346\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_labels.append(cur\_labels\_noim[i])}
\DoxyCodeLine{00347\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ i\ <\ num\_images:}
\DoxyCodeLine{00348\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_image\_features\ =\ image\_features[cur\_image\_idx]}
\DoxyCodeLine{00349\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_image\_idx\ +=\ 1}
\DoxyCodeLine{00350\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_input\_embeds.append(cur\_image\_features)}
\DoxyCodeLine{00351\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_labels.append(torch.full((cur\_image\_features.shape[0],),\ IGNORE\_INDEX,\ device=cur\_labels.device,\ dtype=cur\_labels.dtype))}
\DoxyCodeLine{00352\ }
\DoxyCodeLine{00353\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_input\_embeds\ =\ [x.to(self.device)\ \textcolor{keywordflow}{for}\ x\ \textcolor{keywordflow}{in}\ cur\_new\_input\_embeds]}
\DoxyCodeLine{00354\ }
\DoxyCodeLine{00355\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_input\_embeds\ =\ torch.cat(cur\_new\_input\_embeds)}
\DoxyCodeLine{00356\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_labels\ =\ torch.cat(cur\_new\_labels)}
\DoxyCodeLine{00357\ }
\DoxyCodeLine{00358\ \ \ \ \ \ \ \ \ \ \ \ \ new\_input\_embeds.append(cur\_new\_input\_embeds)}
\DoxyCodeLine{00359\ \ \ \ \ \ \ \ \ \ \ \ \ new\_labels.append(cur\_new\_labels)}
\DoxyCodeLine{00360\ }
\DoxyCodeLine{00361\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Truncate\ sequences\ to\ max\ length\ as\ image\ embeddings\ can\ make\ the\ sequence\ longer}}
\DoxyCodeLine{00362\ \ \ \ \ \ \ \ \ tokenizer\_model\_max\_length\ =\ getattr(self.config,\ \textcolor{stringliteral}{'tokenizer\_model\_max\_length'},\ \textcolor{keywordtype}{None})}
\DoxyCodeLine{00363\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ tokenizer\_model\_max\_length\ \textcolor{keywordflow}{is}\ \textcolor{keywordflow}{not}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{00364\ \ \ \ \ \ \ \ \ \ \ \ \ new\_input\_embeds\ =\ [x[:tokenizer\_model\_max\_length]\ \textcolor{keywordflow}{for}\ x\ \textcolor{keywordflow}{in}\ new\_input\_embeds]}
\DoxyCodeLine{00365\ \ \ \ \ \ \ \ \ \ \ \ \ new\_labels\ =\ [x[:tokenizer\_model\_max\_length]\ \textcolor{keywordflow}{for}\ x\ \textcolor{keywordflow}{in}\ new\_labels]}
\DoxyCodeLine{00366\ }
\DoxyCodeLine{00367\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Combine\ them}}
\DoxyCodeLine{00368\ \ \ \ \ \ \ \ \ max\_len\ =\ max(x.shape[0]\ \textcolor{keywordflow}{for}\ x\ \textcolor{keywordflow}{in}\ new\_input\_embeds)}
\DoxyCodeLine{00369\ \ \ \ \ \ \ \ \ batch\_size\ =\ len(new\_input\_embeds)}
\DoxyCodeLine{00370\ }
\DoxyCodeLine{00371\ \ \ \ \ \ \ \ \ new\_input\_embeds\_padded\ =\ []}
\DoxyCodeLine{00372\ \ \ \ \ \ \ \ \ new\_labels\_padded\ =\ torch.full((batch\_size,\ max\_len),\ IGNORE\_INDEX,\ dtype=new\_labels[0].dtype,\ device=new\_labels[0].device)}
\DoxyCodeLine{00373\ \ \ \ \ \ \ \ \ attention\_mask\ =\ torch.zeros((batch\_size,\ max\_len),\ dtype=attention\_mask.dtype,\ device=attention\_mask.device)}
\DoxyCodeLine{00374\ \ \ \ \ \ \ \ \ position\_ids\ =\ torch.zeros((batch\_size,\ max\_len),\ dtype=position\_ids.dtype,\ device=position\_ids.device)}
\DoxyCodeLine{00375\ }
\DoxyCodeLine{00376\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ i,\ (cur\_new\_embed,\ cur\_new\_labels)\ \textcolor{keywordflow}{in}\ enumerate(zip(new\_input\_embeds,\ new\_labels)):}
\DoxyCodeLine{00377\ \ \ \ \ \ \ \ \ \ \ \ \ cur\_len\ =\ cur\_new\_embed.shape[0]}
\DoxyCodeLine{00378\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ getattr(self.config,\ \textcolor{stringliteral}{'tokenizer\_padding\_side'},\ \textcolor{stringliteral}{'right'})\ ==\ \textcolor{stringliteral}{"{}left"{}}:}
\DoxyCodeLine{00379\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ new\_input\_embeds\_padded.append(torch.cat((}
\DoxyCodeLine{00380\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ torch.zeros((max\_len\ -\/\ cur\_len,\ cur\_new\_embed.shape[1]),\ dtype=cur\_new\_embed.dtype,\ device=cur\_new\_embed.device),}
\DoxyCodeLine{00381\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_embed}
\DoxyCodeLine{00382\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ),\ dim=0))}
\DoxyCodeLine{00383\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ cur\_len\ >\ 0:}
\DoxyCodeLine{00384\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ new\_labels\_padded[i,\ -\/cur\_len:]\ =\ cur\_new\_labels}
\DoxyCodeLine{00385\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ attention\_mask[i,\ -\/cur\_len:]\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{00386\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ position\_ids[i,\ -\/cur\_len:]\ =\ torch.arange(0,\ cur\_len,\ dtype=position\_ids.dtype,\ device=position\_ids.device)}
\DoxyCodeLine{00387\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{00388\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ new\_input\_embeds\_padded.append(torch.cat((}
\DoxyCodeLine{00389\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ cur\_new\_embed,}
\DoxyCodeLine{00390\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ torch.zeros((max\_len\ -\/\ cur\_len,\ cur\_new\_embed.shape[1]),\ dtype=cur\_new\_embed.dtype,\ device=cur\_new\_embed.device)}
\DoxyCodeLine{00391\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ ),\ dim=0))}
\DoxyCodeLine{00392\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ cur\_len\ >\ 0:}
\DoxyCodeLine{00393\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ new\_labels\_padded[i,\ :cur\_len]\ =\ cur\_new\_labels}
\DoxyCodeLine{00394\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ attention\_mask[i,\ :cur\_len]\ =\ \textcolor{keyword}{True}}
\DoxyCodeLine{00395\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ position\_ids[i,\ :cur\_len]\ =\ torch.arange(0,\ cur\_len,\ dtype=position\_ids.dtype,\ device=position\_ids.device)}
\DoxyCodeLine{00396\ }
\DoxyCodeLine{00397\ \ \ \ \ \ \ \ \ new\_input\_embeds\ =\ torch.stack(new\_input\_embeds\_padded,\ dim=0)}
\DoxyCodeLine{00398\ }
\DoxyCodeLine{00399\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \_labels\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{00400\ \ \ \ \ \ \ \ \ \ \ \ \ new\_labels\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{00401\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{00402\ \ \ \ \ \ \ \ \ \ \ \ \ new\_labels\ =\ new\_labels\_padded}
\DoxyCodeLine{00403\ }
\DoxyCodeLine{00404\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \_attention\_mask\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{00405\ \ \ \ \ \ \ \ \ \ \ \ \ attention\_mask\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{00406\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{else}:}
\DoxyCodeLine{00407\ \ \ \ \ \ \ \ \ \ \ \ \ attention\_mask\ =\ attention\_mask.to(dtype=\_attention\_mask.dtype)}
\DoxyCodeLine{00408\ }
\DoxyCodeLine{00409\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{if}\ \_position\_ids\ \textcolor{keywordflow}{is}\ \textcolor{keywordtype}{None}:}
\DoxyCodeLine{00410\ \ \ \ \ \ \ \ \ \ \ \ \ position\_ids\ =\ \textcolor{keywordtype}{None}}
\DoxyCodeLine{00411\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ 결과\ 데이터\ 반환}}
\DoxyCodeLine{00412\ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{return}\ \textcolor{keywordtype}{None},\ position\_ids,\ attention\_mask,\ past\_key\_values,\ new\_input\_embeds,\ new\_labels}
\DoxyCodeLine{00413\ }

\end{DoxyCode}
Here is the call graph for this function\+:
% FIG 13
Here is the caller graph for this function\+:
% FIG 14


\doxysubsection{Member Data Documentation}
\Hypertarget{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a64f3ed33345e5078777ce464de4ea71b}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!config@{config}}
\index{config@{config}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{config}{config}}
{\footnotesize\ttfamily \label{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a64f3ed33345e5078777ce464de4ea71b} 
llava.\+model.\+llava\+\_\+arch.\+Llava\+Meta\+For\+Causal\+LM.\+config = cur\+\_\+new\+\_\+embed.\+shape\mbox{[}0\mbox{]}\hspace{0.3cm}{\ttfamily [inherited]}}



Definition at line \mbox{\hyperlink{llava__arch_8py_source_l00292}{292}} of file \mbox{\hyperlink{llava__arch_8py_source}{llava\+\_\+arch.\+py}}.

\Hypertarget{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a171d4101cfae1ec6839d83d2e817a0f7}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!config\_class@{config\_class}}
\index{config\_class@{config\_class}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{config\_class}{config\_class}}
{\footnotesize\ttfamily \label{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a171d4101cfae1ec6839d83d2e817a0f7} 
llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM.\+config\+\_\+class = \mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_config}{Llava\+Mpt\+Config}}\hspace{0.3cm}{\ttfamily [static]}}



Definition at line \mbox{\hyperlink{llava__mpt_8py_source_l00073}{73}} of file \mbox{\hyperlink{llava__mpt_8py_source}{llava\+\_\+mpt.\+py}}.

\Hypertarget{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a28245ac877e4cd4d45741a71216847bb}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!lm\_head@{lm\_head}}
\index{lm\_head@{lm\_head}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{lm\_head}{lm\_head}}
{\footnotesize\ttfamily \label{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a28245ac877e4cd4d45741a71216847bb} 
llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM.\+lm\+\_\+head = torch.\+nn.\+Linear(config.\+hidden\+\_\+size, config.\+vocab\+\_\+size, bias=False)}



Definition at line \mbox{\hyperlink{llava__mpt_8py_source_l00080}{80}} of file \mbox{\hyperlink{llava__mpt_8py_source}{llava\+\_\+mpt.\+py}}.

\Hypertarget{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a79bba18fb37b45a452b5c331e21836f2}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!supports\_gradient\_checkpointing@{supports\_gradient\_checkpointing}}
\index{supports\_gradient\_checkpointing@{supports\_gradient\_checkpointing}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{supports\_gradient\_checkpointing}{supports\_gradient\_checkpointing}}
{\footnotesize\ttfamily \label{classllava__mpt_1_1_llava_mpt_for_causal_l_m_a79bba18fb37b45a452b5c331e21836f2} 
bool llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM.\+supports\+\_\+gradient\+\_\+checkpointing = True\hspace{0.3cm}{\ttfamily [static]}}



Definition at line \mbox{\hyperlink{llava__mpt_8py_source_l00074}{74}} of file \mbox{\hyperlink{llava__mpt_8py_source}{llava\+\_\+mpt.\+py}}.

\Hypertarget{classllava__mpt_1_1_llava_mpt_for_causal_l_m_ac42052a3f618ac1d4a164273dbf0c25f}\index{llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}!transformer@{transformer}}
\index{transformer@{transformer}!llava\_mpt.LlavaMptForCausalLM@{llava\_mpt.LlavaMptForCausalLM}}
\doxysubsubsection{\texorpdfstring{transformer}{transformer}}
{\footnotesize\ttfamily \label{classllava__mpt_1_1_llava_mpt_for_causal_l_m_ac42052a3f618ac1d4a164273dbf0c25f} 
llava\+\_\+mpt.\+Llava\+Mpt\+For\+Causal\+LM.\+transformer = \mbox{\hyperlink{classllava__mpt_1_1_llava_mpt_model}{Llava\+Mpt\+Model}}(\mbox{\hyperlink{classllava_1_1model_1_1llava__arch_1_1_llava_meta_for_causal_l_m_a64f3ed33345e5078777ce464de4ea71b}{config}})}



Definition at line \mbox{\hyperlink{llava__mpt_8py_source_l00079}{79}} of file \mbox{\hyperlink{llava__mpt_8py_source}{llava\+\_\+mpt.\+py}}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
language\+\_\+model/\mbox{\hyperlink{llava__mpt_8py}{llava\+\_\+mpt.\+py}}\end{DoxyCompactItemize}
