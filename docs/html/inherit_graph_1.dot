digraph "Graphical Class Hierarchy"
{
 // LATEX_PDF_SIZE
  bgcolor="transparent";
  edge [fontname=Helvetica,fontsize=10,labelfontname=Helvetica,labelfontsize=10];
  node [fontname=Helvetica,fontsize=10,shape=box,height=0.2,width=0.4];
  rankdir="LR";
  Node0 [id="Node000000",label="nn.Module",height=0.2,width=0.4,color="grey60", fillcolor="#E0E0E0", style="filled",tooltip=" "];
  Node0 -> Node1 [id="edge2_Node000000_Node000001",dir="back",color="steelblue1",style="solid",tooltip=" "];
  Node1 [id="Node000001",label="clip.model.AttentionPool2d",height=0.2,width=0.4,color="grey40", fillcolor="white", style="filled",URL="$classclip_1_1model_1_1_attention_pool2d.html",tooltip="Implements a 2D attention pooling layer."];
  Node0 -> Node2 [id="edge3_Node000000_Node000002",dir="back",color="steelblue1",style="solid",tooltip=" "];
  Node2 [id="Node000002",label="clip.model.Bottleneck",height=0.2,width=0.4,color="grey40", fillcolor="white", style="filled",URL="$classclip_1_1model_1_1_bottleneck.html",tooltip="Implements a ResNet bottleneck block with optional downsampling."];
  Node0 -> Node3 [id="edge4_Node000000_Node000003",dir="back",color="steelblue1",style="solid",tooltip=" "];
  Node3 [id="Node000003",label="clip.model.CLIP",height=0.2,width=0.4,color="grey40", fillcolor="white", style="filled",URL="$classclip_1_1model_1_1_c_l_i_p.html",tooltip="Implements the CLIP model, combining image and text encoders."];
  Node0 -> Node4 [id="edge5_Node000000_Node000004",dir="back",color="steelblue1",style="solid",tooltip=" "];
  Node4 [id="Node000004",label="clip.model.ModifiedResNet",height=0.2,width=0.4,color="grey40", fillcolor="white", style="filled",URL="$classclip_1_1model_1_1_modified_res_net.html",tooltip="A modified ResNet model for CLIP."];
  Node0 -> Node5 [id="edge6_Node000000_Node000005",dir="back",color="steelblue1",style="solid",tooltip=" "];
  Node5 [id="Node000005",label="clip.model.QuickGELU",height=0.2,width=0.4,color="grey40", fillcolor="white", style="filled",URL="$classclip_1_1model_1_1_quick_g_e_l_u.html",tooltip="Implements a fast approximation of the GELU activation function."];
  Node0 -> Node6 [id="edge7_Node000000_Node000006",dir="back",color="steelblue1",style="solid",tooltip=" "];
  Node6 [id="Node000006",label="clip.model.ResidualAttention\lBlock",height=0.2,width=0.4,color="grey40", fillcolor="white", style="filled",URL="$classclip_1_1model_1_1_residual_attention_block.html",tooltip="Implements a residual attention block with multi-head self-attention and MLP layers."];
  Node0 -> Node7 [id="edge8_Node000000_Node000007",dir="back",color="steelblue1",style="solid",tooltip=" "];
  Node7 [id="Node000007",label="clip.model.Transformer",height=0.2,width=0.4,color="grey40", fillcolor="white", style="filled",URL="$classclip_1_1model_1_1_transformer.html",tooltip="Implements a Transformer model with residual attention blocks."];
  Node0 -> Node8 [id="edge9_Node000000_Node000008",dir="back",color="steelblue1",style="solid",tooltip=" "];
  Node8 [id="Node000008",label="clip.model.VisionTransformer",height=0.2,width=0.4,color="grey40", fillcolor="white", style="filled",URL="$classclip_1_1model_1_1_vision_transformer.html",tooltip="Implements a Vision Transformer model."];
}
