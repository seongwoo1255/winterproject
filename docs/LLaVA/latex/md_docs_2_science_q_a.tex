\chapter{Science\+QA}
\hypertarget{md_docs_2_science_q_a}{}\label{md_docs_2_science_q_a}\index{ScienceQA@{ScienceQA}}
\label{md_docs_2_science_q_a_autotoc_md54}%
\Hypertarget{md_docs_2_science_q_a_autotoc_md54}%
\hypertarget{md_docs_2_science_q_a_autotoc_md55}{}\doxysubsubsection{\texorpdfstring{Prepare Data}{Prepare Data}}\label{md_docs_2_science_q_a_autotoc_md55}

\begin{DoxyEnumerate}
\item Please see Science\+QA \href{https://github.com/lupantech/ScienceQA}{\texttt{ repo}} for setting up the dataset.
\item Generate Science\+QA dataset for LLa\+VA conversation-\/style format.
\end{DoxyEnumerate}


\begin{DoxyCode}{0}
\DoxyCodeLine{python\ scripts/convert\_sqa\_to\_llava.py\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ convert\_to\_llava\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/base-\/dir\ /path/to/ScienceQA/data/scienceqa\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/prompt-\/format\ "{}QCM-\/LEA"{}\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/split\ \{train,val,minival,test,minitest\}}

\end{DoxyCode}
\hypertarget{md_docs_2_science_q_a_autotoc_md56}{}\doxysubsubsection{\texorpdfstring{Training}{Training}}\label{md_docs_2_science_q_a_autotoc_md56}

\begin{DoxyEnumerate}
\item Pretraining
\end{DoxyEnumerate}

You can download our pretrained projector weights from our \mbox{[}Model Zoo\mbox{]}(), or train your own projector weights using \href{https://github.com/haotian-liu/LLaVA/blob/main/scripts/pretrain.sh}{\texttt{ {\ttfamily pretrain.\+sh}}}.


\begin{DoxyEnumerate}
\item Finetuning
\end{DoxyEnumerate}

See \href{https://github.com/haotian-liu/LLaVA/blob/main/scripts/finetune_sqa.sh}{\texttt{ {\ttfamily finetune\+\_\+sqa.\+sh}}}.\hypertarget{md_docs_2_science_q_a_autotoc_md57}{}\doxysubsubsection{\texorpdfstring{Evaluation}{Evaluation}}\label{md_docs_2_science_q_a_autotoc_md57}

\begin{DoxyEnumerate}
\item Multiple-\/\+GPU inference You may evaluate this with multiple GPUs, and concatenate the generated jsonl files. Please refer to our script for \href{https://github.com/haotian-liu/LLaVA/blob/main/scripts/sqa_eval_batch.sh}{\texttt{ batch evaluation}} and \href{https://github.com/haotian-liu/LLaVA/blob/main/scripts/sqa_eval_gather.sh}{\texttt{ results gathering}}.
\item Single-\/\+GPU inference
\end{DoxyEnumerate}

(a) Generate LLa\+VA responses on Science\+QA dataset


\begin{DoxyCode}{0}
\DoxyCodeLine{python\ -\/m\ llava.eval.model\_vqa\_science\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/model-\/path\ liuhaotian/llava-\/lcs558k-\/scienceqa-\/vicuna-\/13b-\/v1.3\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/question-\/file\ /path/to/ScienceQA/data/scienceqa/llava\_test\_QCM-\/LEA.json\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/image-\/folder\ /path/to/ScienceQA/data/scienceqa/images/test\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/answers-\/file\ vqa/results/ScienceQA/test\_llava-\/13b.jsonl\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/conv-\/mode\ llava\_v1}

\end{DoxyCode}


(b) Evaluate the generated responses


\begin{DoxyCode}{0}
\DoxyCodeLine{python\ eval\_science\_qa.py\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/base-\/dir\ /path/to/ScienceQA/data/scienceqa\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/result-\/file\ vqa/results/ScienceQA/test\_llava-\/13b.jsonl\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/output-\/file\ vqa/results/ScienceQA/test\_llava-\/13b\_output.json\ \(\backslash\)}
\DoxyCodeLine{\ \ \ \ -\/-\/output-\/result\ vqa/results/ScienceQA/test\_llava-\/13b\_result.json\ \(\backslash\)}

\end{DoxyCode}


For reference, we attach our prediction file \href{https://github.com/haotian-liu/LLaVA/blob/main/llava/eval/table/results/test_sqa_llava_lcs_558k_sqa_12e_vicuna_v1_3_13b.json}{\texttt{ {\ttfamily test\+\_\+sqa\+\_\+llava\+\_\+lcs\+\_\+558k\+\_\+sqa\+\_\+12e\+\_\+vicuna\+\_\+v1\+\_\+3\+\_\+13b.\+json}}} and \href{https://github.com/haotian-liu/LLaVA/blob/main/llava/eval/table/results/test_sqa_llava_13b_v0.json}{\texttt{ {\ttfamily test\+\_\+sqa\+\_\+llava\+\_\+13b\+\_\+v0.\+json}}} for comparison when reproducing our results, as well as for further analysis in detail. 