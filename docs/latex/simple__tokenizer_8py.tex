\doxysection{simple\+\_\+tokenizer.\+py File Reference}
\hypertarget{simple__tokenizer_8py}{}\label{simple__tokenizer_8py}\index{simple\_tokenizer.py@{simple\_tokenizer.py}}


Implements a simple Byte Pair Encoding (BPE) tokenizer.  


\doxysubsubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{classclip_1_1simple__tokenizer_1_1_simple_tokenizer}{clip.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer}}
\begin{DoxyCompactList}\small\item\em Implements a simple Byte Pair Encoding (BPE) tokenizer. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsubsection*{Namespaces}
\begin{DoxyCompactItemize}
\item 
namespace \mbox{\hyperlink{namespaceclip}{clip}}
\item 
namespace \mbox{\hyperlink{namespaceclip_1_1simple__tokenizer}{clip.\+simple\+\_\+tokenizer}}
\end{DoxyCompactItemize}
\doxysubsubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespaceclip_1_1simple__tokenizer_a60caf340a81c7885c3aac41bf5eeca3d}{clip.\+simple\+\_\+tokenizer.\+default\+\_\+bpe}} ()
\begin{DoxyCompactList}\small\item\em Returns the default path to the BPE vocabulary file. \end{DoxyCompactList}\item 
\mbox{\hyperlink{namespaceclip_1_1simple__tokenizer_a05809bce5e2074836ebe6d431005a0c9}{clip.\+simple\+\_\+tokenizer.\+bytes\+\_\+to\+\_\+unicode}} ()
\begin{DoxyCompactList}\small\item\em Creates a mapping between bytes and Unicode characters. \end{DoxyCompactList}\item 
\mbox{\hyperlink{namespaceclip_1_1simple__tokenizer_a70c67c878a64d25b2a44feaaa0559a55}{clip.\+simple\+\_\+tokenizer.\+get\+\_\+pairs}} (word)
\begin{DoxyCompactList}\small\item\em Extracts symbol pairs from a given word. \end{DoxyCompactList}\item 
\mbox{\hyperlink{namespaceclip_1_1simple__tokenizer_a44a7e4043bef03185865f4c074e9df31}{clip.\+simple\+\_\+tokenizer.\+basic\+\_\+clean}} (text)
\begin{DoxyCompactList}\small\item\em Cleans the input text by fixing text and unescaping HTML entities. \end{DoxyCompactList}\item 
\mbox{\hyperlink{namespaceclip_1_1simple__tokenizer_af38df56fc6ba00cac41934baaad0fd22}{clip.\+simple\+\_\+tokenizer.\+whitespace\+\_\+clean}} (text)
\begin{DoxyCompactList}\small\item\em Cleans whitespace from the input text. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Implements a simple Byte Pair Encoding (BPE) tokenizer. 

This tokenizer is used for encoding and decoding text using BPE with a predefined vocabulary. @dependencies
\begin{DoxyItemize}
\item ftfy
\item regex
\item gzip
\item functools
\item os 
\end{DoxyItemize}

Definition in file \mbox{\hyperlink{simple__tokenizer_8py_source}{simple\+\_\+tokenizer.\+py}}.

